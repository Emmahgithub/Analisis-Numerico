{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+rCc4m/EtwTNrIB1CW9Wi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emmahgithub/Analisis-Numerico-2025-1/blob/main/23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Tarea 1 Analisis Numerico</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Blue\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>MARTINEZ ROSAS ZAYDE YAMILE</i></h5>\n",
        "  <h5 align=\"center\"><i>CAMACHO MARIN ANA KAREN</i></h5>\n",
        "  <h5 align=\"center\"><i>LÓPEZ AGUIRRE ROBERTO OCELOTZIN</i></h5>\n",
        "  <h5 align=\"center\"><i>VARGAS BAUTISTA EMMANUEL</i></h5>\n",
        "  </font>"
      ],
      "metadata": {
        "id": "jRRNsGg3iyH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ocupamos\n",
        "import numpy as np\n",
        "\n",
        "# Sustitucion hacia atras (Codigo ayudante)\n",
        "def SustitucionAtras(Mat, b):\n",
        "    n = Mat.shape[0]\n",
        "    x = np.zeros(n)\n",
        "    for i in range(n-1, -1, -1):\n",
        "        SumCum = 0.0\n",
        "        for j in range(i+1, n):\n",
        "            SumCum += Mat[i, j] * x[j]\n",
        "        x[i] = (b[i] - SumCum) / Mat[i, i]\n",
        "    return x\n",
        "\n",
        "# Eliminar hacia adelante (Gauss) (Codigo ayudante - Implementacion propia)\n",
        "def gaussian_elimination(A, b):\n",
        "    A = A.astype(float)\n",
        "    b = b.astype(float)\n",
        "    n = len(A)\n",
        "    for i in range(n):\n",
        "        pivot = A[i, i]\n",
        "        A[i] = A[i] / pivot\n",
        "        b[i] = b[i] / pivot\n",
        "        for j in range(i + 1, n):\n",
        "            factor = A[j, i]\n",
        "            A[j] = A[j] - factor * A[i]\n",
        "            b[j] = b[j] - factor * b[i]\n",
        "    return A, b\n"
      ],
      "metadata": {
        "id": "aMSLTIIsAK9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Solución exacta\n",
        "x_exact = np.array([1, 1])\n",
        "\n",
        "print(f\"{'k':>2} {'epsilon':>10} {'x1':>12} {'x2':>12} {'Error':>12}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Experimento para diferentes valores de epsilon\n",
        "for k in range(1, 11):\n",
        "    eps = 10**(-2*k)\n",
        "    A = np.array([[eps, 1], [1, 1]])\n",
        "    b = np.array([1 + eps, 2])\n",
        "\n",
        "    # Copias para no modificar A, b original\n",
        "    A_mod, b_mod = gaussian_elimination(A.copy(), b.copy())\n",
        "    x_num = SustitucionAtras(A_mod, b_mod)\n",
        "\n",
        "    error = np.linalg.norm(x_num - x_exact)\n",
        "    print(f\"{k:2d} {eps:10.1e} {x_num[0]:12.8f} {x_num[1]:12.8f} {error:12.4}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxRryBqqF1Zo",
        "outputId": "4137d312-1001-4e03-8c37-dcd5f07f9730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " k    epsilon           x1           x2        Error\n",
            "==================================================\n",
            " 1    1.0e-02   1.00000000   1.00000000          0.0\n",
            " 2    1.0e-04   1.00000000   1.00000000          0.0\n",
            " 3    1.0e-06   1.00000000   1.00000000          0.0\n",
            " 4    1.0e-08   1.00000000   1.00000000     1.11e-16\n",
            " 5    1.0e-10   1.00000000   1.00000000          0.0\n",
            " 6    1.0e-12   0.99987793   1.00000000    0.0001221\n",
            " 7    1.0e-14   1.00000000   1.00000000          0.0\n",
            " 8    1.0e-16   2.00000000   1.00000000          1.0\n",
            " 9    1.0e-18   0.00000000   1.00000000          1.0\n",
            "10    1.0e-20   0.00000000   1.00000000          1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar conforme k aumenta $\\epsilon$ decrese y entre mas pequeño se hace llega un punto donde el error aumenta muchisimo al punto de ya no dar un resultado ni siquiera cercano"
      ],
      "metadata": {
        "id": "CWs2LEJ_IA5Z"
      }
    }
  ]
}